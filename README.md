# Machine Learning Foundations

Here is a brief summary of what was taught in this course: 

- Regression Problems

- Classification Problems

- Classification - Logistic Regression
    1.Sigmoid function model
    2. Logistic regression cost (loss) function
    3. Decision boundary
    4. Nonlinearly separable data
    5. Regularized logistic regression 
    
- Neural Networks
    1. NN - non-linear classifier
    2. Neuron model: logistic unit
    3. NN - binary versus multi-class classification
    4. Cost function (with or without regularization)
    5. NN learning - Error Backpropagation algorithm

- Model Selection and Validation - Bias Vs. Variance 
    1. Model selection: Bias vs. variance
    2. Learning curves
    3. K –fold Cross Validation
    4. Ensemble classifiers
    5. k-Nearest Neighbor (k-NN) classifier
    6. Model-centric vs Data-centric ML

- SUPPORT VECTOR MACHINE (SVM)
    1. Linear Support Vector Machine (SVM)
    2. Nonlinear SVM - Gaussian RBF Kernel
    3. Performance evaluation – confusion matrix
    4. Class imbalance problem

- Naïve Bayes & Decision Tree classifiers

- Unsupervised Learning (K-Means Clustering and PCA) 

- Anomaly detection

- Convolutional Neural Networks (CONVNETS)
    1. Deep Neural Networks
    2. Convolutional Neural Networks (CNN) - basic building blocks
    3. Classical CNN – LeNet-5, AlexNet, VGG
    4. Visualization of what convolutional layers learn

- Sequence Models and Time Series Forecasting
    1. Sequence models – motivation
    2. Recurrent Neural Networks (RNN)
    3. Backpropagation through time
    4. Long-Short Term Memory (LSTM)
    5. Time Series Forecasting

- Recommender Systems
    1. Problem formulation
    2. Content-based recommendation systems
    3. Collaborative filtering learning algorithm

# Evaluation

This course consisted in two assignments and one exam. 

FINAL GRADE: Project 1: 18.7; Project 2: 17.5; Exam: 10.6; FINAL MARK: 14.
